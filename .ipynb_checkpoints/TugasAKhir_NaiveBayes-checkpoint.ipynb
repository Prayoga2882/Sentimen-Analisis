{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42a1c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "# from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "188a37c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>retweet</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-18 23:17:14 SE Asia Standard Time</td>\n",
       "      <td>1.170000e+18</td>\n",
       "      <td>njmyg_</td>\n",
       "      <td>@sunnova1324 @tanyainrl iya sih.. tapi maksud ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-18 23:07:06 SE Asia Standard Time</td>\n",
       "      <td>1.310000e+18</td>\n",
       "      <td>urbbyyyyyyyy</td>\n",
       "      <td>males kuliah online temennya sikit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18 23:05:21 SE Asia Standard Time</td>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>risyaanggun</td>\n",
       "      <td>tumbenan td kuliah online dosennya minta join ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-18 22:58:58 SE Asia Standard Time</td>\n",
       "      <td>1.240000e+18</td>\n",
       "      <td>nyctophilexxx</td>\n",
       "      <td>@monsouleil nangis krn kecapean kuliah online ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-18 22:50:53 SE Asia Standard Time</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>anisanwl</td>\n",
       "      <td>Apa hanya aku yang merasa semenjak kuliah onli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  created_at       user_id       username  \\\n",
       "0  2020-11-18 23:17:14 SE Asia Standard Time  1.170000e+18         njmyg_   \n",
       "1  2020-11-18 23:07:06 SE Asia Standard Time  1.310000e+18   urbbyyyyyyyy   \n",
       "2  2020-11-18 23:05:21 SE Asia Standard Time  1.330000e+18    risyaanggun   \n",
       "3  2020-11-18 22:58:58 SE Asia Standard Time  1.240000e+18  nyctophilexxx   \n",
       "4  2020-11-18 22:50:53 SE Asia Standard Time  1.090000e+18       anisanwl   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  @sunnova1324 @tanyainrl iya sih.. tapi maksud ...              0   \n",
       "1                 males kuliah online temennya sikit              0   \n",
       "2  tumbenan td kuliah online dosennya minta join ...              0   \n",
       "3  @monsouleil nangis krn kecapean kuliah online ...              1   \n",
       "4  Apa hanya aku yang merasa semenjak kuliah onli...              0   \n",
       "\n",
       "   retweets_count  likes_count  retweet  polarity  \n",
       "0               0            0    False  positive  \n",
       "1               0            0    False  negative  \n",
       "2               0            0    False  negative  \n",
       "3               0            0    False  negative  \n",
       "4               0            1    False  negative  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Dataset\n",
    "# data_frame = pd.read_csv('tweets_data.csv')\n",
    "data_frame = pd.read_csv('Dataset/tweets_data.csv')\n",
    "# data_frame = data_frame[:5000]\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "994d38a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b01754",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd7c7d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    12733\n",
       "1.0     8441\n",
       "0.0     2525\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['polarity'].replace(('neutral', 'positive', 'negative'), (0, 1, 2), inplace=True)\n",
    "data_frame['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74cccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_frame['tweet'].values.tolist()\n",
    "label = data_frame['polarity'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fe27d",
   "metadata": {},
   "source": [
    "# Split Data train dan Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96911694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data training: 20000\n",
      "Jumlah data testing: 5000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, y_train, y_test = train_test_split(data, label, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(f'Jumlah data training: {len(train_X)}')\n",
    "print(f'Jumlah data testing: {len(test_X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb8bcf",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f848b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text_clean = re.sub(r'@[A-Za-z0-9]+', '', str(text)) # Hapus Mention\n",
    "    text_clean = re.sub(r'#[A-Za-z0-9]+', '', text_clean) # Hapus hashtag\n",
    "    text_clean = re.sub(r'RT[\\s]', '', text_clean) # Hapus RT\n",
    "    text_clean = re.sub(r\"http\\S+\", '', text_clean) # Hapus link\n",
    "    text_clean = re.sub(r'[0-9]+', '', text_clean) # Hapus angka\n",
    "    text_clean = text_clean.replace('\\n', ' ') # Ganti enter ke spasi\n",
    "    text_clean = text_clean.translate(str.maketrans('', '', string.punctuation)) # Hapus tanda baca\n",
    "    text_clean = text_clean.strip(' ') # Hapus spasi tdk jelas\n",
    "    return text_clean\n",
    "\n",
    "def casefoldingText(text):\n",
    "    lwr = text\n",
    "    map(str.lower, lwr)\n",
    "    text = lwr\n",
    "    return text\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "def tokenizingText(text): \n",
    "    text = tokenizer.tokenize(text)                  \n",
    "    return text\n",
    "\n",
    "def filteringText(text):\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered \n",
    "    return text\n",
    "\n",
    "def stemmingText(text): \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7290d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    tweet_Cleaning = cleaningText(tweet)\n",
    "    tweet_CaseFolding = casefoldingText(tweet_Cleaning)\n",
    "    tweet_Tokenizing = tokenizingText(tweet_CaseFolding)\n",
    "    tweet_Filtering = filteringText(tweet_Tokenizing)\n",
    "#     tweet_Stemming = stemmingText(tweet_Filtering)    \n",
    "    return tweet_Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai: 21:35:10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_jkt = pytz.timezone('Asia/Jakarta')\n",
    "print(\"Mulai:\", datetime.now(time_jkt).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "#preprocess data train\n",
    "preprocessed_text = []\n",
    "for i in range(0, len(train_X)):\n",
    "    preprocessed_text.append(process_tweet(train_X[i]))\n",
    "\n",
    "X_train = preprocessed_text\n",
    "\n",
    "# Pkl_Filename = \"X_train.pkl\"  \n",
    "\n",
    "# with open(Pkl_Filename, 'wb') as file:  \n",
    "#     pickle.dump(X_train, file)\n",
    "\n",
    "\n",
    "#preprocess data test\n",
    "preprocessed_text = []\n",
    "for i in range(0, len(test_X)):\n",
    "    preprocessed_text.append(process_tweet(test_X[i]))\n",
    "\n",
    "X_test = preprocessed_text\n",
    "\n",
    "# Pkl_Filename = \"y_train.pkl\"  \n",
    "\n",
    "# with open(Pkl_Filename, 'wb') as file:  \n",
    "#     pickle.dump(y_train, file)\n",
    "print(\"Selesai:\", datetime.now(time_jkt).strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3833e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
